{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af3c31-7e0e-4f5a-bb56-ac48c23aea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "\n",
    "# URL da página principal com as empresas\n",
    "BASE_URL = \"https://statusinvest.com.br/ipo/acoes\"\n",
    "\n",
    "# Cabeçalhos para simular um navegador\n",
    "headers = {\n",
    "    \"User-Agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                   \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                   \"Chrome/91.0.4472.124 Safari/537.36\")\n",
    "}\n",
    "\n",
    "# Diretório para salvar os PDFs\n",
    "download_folder = \"../data/minuta/\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# Função para baixar o PDF\n",
    "def download_pdf(pdf_url, filename):\n",
    "    try:\n",
    "        # Faz a requisição para o PDF\n",
    "        pdf_response = requests.get(pdf_url, headers=headers)\n",
    "        pdf_response.raise_for_status()  # Verifica se houve erro na requisição\n",
    "        with open(filename, 'wb') as pdf_file:\n",
    "            pdf_file.write(pdf_response.content)  # Salva o conteúdo como PDF\n",
    "        print(f\"  PDF baixado com sucesso: {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  Erro ao baixar o PDF: {e}\")\n",
    "\n",
    "# 1. Obter a página principal e extrair os blocos de empresas com status \"Protocolado\" (data-status=\"0\")\n",
    "response = requests.get(BASE_URL, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao carregar a página principal: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Filtra os blocos das empresas com status \"Protocolado\"\n",
    "company_divs = soup.find_all(\"div\", attrs={\"data-status\": \"0\"})\n",
    "\n",
    "# Extrai os links de cada empresa (usamos um conjunto para evitar duplicatas)\n",
    "company_links = set()\n",
    "for div in company_divs:\n",
    "    a_tag = div.find(\"a\", href=True)\n",
    "    if a_tag:\n",
    "        company_links.add(a_tag[\"href\"])\n",
    "\n",
    "print(\"Links das empresas com status Protocolado encontrados:\")\n",
    "for comp_link in company_links:\n",
    "    # Se o link não for absoluto, junta com a URL base\n",
    "    full_company_link = comp_link if comp_link.startswith(\"http\") else urljoin(BASE_URL, comp_link)\n",
    "    print(full_company_link)\n",
    "\n",
    "print(\"\\nAgora, vamos obter os links de PDF para cada empresa:\")\n",
    "\n",
    "# 2. Para cada empresa, acessar sua página e procurar o link para a página da CVM (que já é o link para baixar o PDF)\n",
    "for comp_link in company_links:\n",
    "    full_company_link = comp_link if comp_link.startswith(\"http\") else urljoin(BASE_URL, comp_link)\n",
    "    print(f\"\\nEmpresa: {full_company_link}\")\n",
    "\n",
    "    comp_response = requests.get(full_company_link, headers=headers)\n",
    "    if comp_response.status_code != 200:\n",
    "        print(f\"  Erro ao acessar a página da empresa: {comp_response.status_code}\")\n",
    "        continue\n",
    "\n",
    "    comp_soup = BeautifulSoup(comp_response.text, 'html.parser')\n",
    "    \n",
    "    # Procura por todos os links que contenham \"sistemas.cvm.gov.br/dados/ofeanal\"\n",
    "    cvm_link_tags = comp_soup.find_all('a', href=lambda href: href and \"sistemas.cvm.gov.br/dados/ofeanal\" in href)\n",
    "    \n",
    "    if not cvm_link_tags:\n",
    "        print(\"  Nenhum link da CVM encontrado nesta empresa.\")\n",
    "        continue\n",
    "\n",
    "    # Para cada link da CVM encontrado, agora vamos tentar acessar diretamente o PDF\n",
    "    for cvm_tag in cvm_link_tags:\n",
    "        cvm_url = cvm_tag['href']\n",
    "        print(f\"  Página CVM: {cvm_url}\")\n",
    "\n",
    "        # Verifica se o link para o PDF é válido\n",
    "        if cvm_url.lower().endswith('.pdf'):\n",
    "            # Obtém o nome da empresa da URL e remove caracteres especiais\n",
    "            company_name = full_company_link.split(\"/\")[-1].replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "            filename = os.path.join(download_folder, f\"{company_name}_{cvm_url.split('/')[-1]}\")\n",
    "            download_pdf(cvm_url, filename)\n",
    "        else:\n",
    "            print(\"    O link não é um PDF direto.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac36792-f6b8-4484-859b-784b4910a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env_personalizado",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
